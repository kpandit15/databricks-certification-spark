{"cells":[{"cell_type":"markdown","source":["* Inner Join - **join** or **inner join**\n* **Left** or **Right Outer Join**\n* Full Outer Join - **a left outer join b** union **a right outer join b**\n* Cross Join\n* Spark Data Frames have a function called `join`. It can be used to perform inner or outer or full outer join.\n* We need to specify **join condition** for Inner or Outer or Full Outer Join."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7d8d2ec-fd15-4069-ac4d-dcfc555bc98d"}}},{"cell_type":"code","source":["%run \"./02 Setup Data Sets to perform joins\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c3f8c5a5-2792-4d5b-bb8f-dc6eea51ab77"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------+--------------------+-------------------+---------+-------------------+\n|course_id|        course_title|course_published_dt|is_active|    last_updated_ts|\n+---------+--------------------+-------------------+---------+-------------------+\n|        1|    Mastering Python|         2021-01-14|     true|2021-02-18 16:57:25|\n|        2|Data Engineering ...|         2021-02-10|     true|2021-03-05 12:07:33|\n|        3|   Mastering Pyspark|         2021-01-07|     true|2021-04-06 10:05:42|\n|        4|      AWS Essentials|         2021-03-19|    false|2021-04-10 02:25:36|\n|        5|          Docker 101|         2021-02-28|     true|2021-03-21 07:18:52|\n+---------+--------------------+-------------------+---------+-------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+--------------------+-------------------+---------+-------------------+\ncourse_id|        course_title|course_published_dt|is_active|    last_updated_ts|\n+---------+--------------------+-------------------+---------+-------------------+\n        1|    Mastering Python|         2021-01-14|     true|2021-02-18 16:57:25|\n        2|Data Engineering ...|         2021-02-10|     true|2021-03-05 12:07:33|\n        3|   Mastering Pyspark|         2021-01-07|     true|2021-04-06 10:05:42|\n        4|      AWS Essentials|         2021-03-19|    false|2021-04-10 02:25:36|\n        5|          Docker 101|         2021-02-28|     true|2021-03-21 07:18:52|\n+---------+--------------------+-------------------+---------+-------------------+\n\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+---------------+--------------+--------------------+\n|user_id|user_first_name|user_last_name|          user_email|\n+-------+---------------+--------------+--------------------+\n|      1|         Sandra|        Karpov|    skarpov0@ovh.net|\n|      2|           Kari|        Dearth|kdearth1@so-net.n...|\n|      3|         Joanna|      Spennock|jspennock2@redcro...|\n|      4|         Hirsch|       Conaboy|hconaboy3@barnesa...|\n|      5|         Loreen|         Malin|lmalin4@independe...|\n|      6|           Augy|      Christon|  achriston5@mlb.com|\n|      7|         Trudey|       Choupin|     tchoupin6@de.vu|\n|      8|         Nadine|     Grimsdell|ngrimsdell7@sohu.com|\n|      9|        Vassily|         Tamas|vtamas8@businessw...|\n|     10|          Wells|      Simpkins|wsimpkins9@amazon...|\n+-------+---------------+--------------+--------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+---------------+--------------+--------------------+\nuser_id|user_first_name|user_last_name|          user_email|\n+-------+---------------+--------------+--------------------+\n      1|         Sandra|        Karpov|    skarpov0@ovh.net|\n      2|           Kari|        Dearth|kdearth1@so-net.n...|\n      3|         Joanna|      Spennock|jspennock2@redcro...|\n      4|         Hirsch|       Conaboy|hconaboy3@barnesa...|\n      5|         Loreen|         Malin|lmalin4@independe...|\n      6|           Augy|      Christon|  achriston5@mlb.com|\n      7|         Trudey|       Choupin|     tchoupin6@de.vu|\n      8|         Nadine|     Grimsdell|ngrimsdell7@sohu.com|\n      9|        Vassily|         Tamas|vtamas8@businessw...|\n     10|          Wells|      Simpkins|wsimpkins9@amazon...|\n+-------+---------------+--------------+--------------------+\n\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------------------+-------+---------+----------+\n|course_enrolment_id|user_id|course_id|price_paid|\n+-------------------+-------+---------+----------+\n|                  1|     10|        2|      9.99|\n|                  2|      5|        2|      9.99|\n|                  3|      7|        5|     10.99|\n|                  4|      9|        2|      9.99|\n|                  5|      8|        2|      9.99|\n|                  6|      5|        5|     10.99|\n|                  7|      4|        5|     10.99|\n|                  8|      7|        3|     10.99|\n|                  9|      8|        5|     10.99|\n|                 10|      3|        3|     10.99|\n|                 11|      7|        5|     10.99|\n|                 12|      3|        2|      9.99|\n|                 13|      5|        2|      9.99|\n|                 14|      4|        3|     10.99|\n|                 15|      8|        2|      9.99|\n+-------------------+-------+---------+----------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------------+-------+---------+----------+\ncourse_enrolment_id|user_id|course_id|price_paid|\n+-------------------+-------+---------+----------+\n                  1|     10|        2|      9.99|\n                  2|      5|        2|      9.99|\n                  3|      7|        5|     10.99|\n                  4|      9|        2|      9.99|\n                  5|      8|        2|      9.99|\n                  6|      5|        5|     10.99|\n                  7|      4|        5|     10.99|\n                  8|      7|        3|     10.99|\n                  9|      8|        5|     10.99|\n                 10|      3|        3|     10.99|\n                 11|      7|        5|     10.99|\n                 12|      3|        2|      9.99|\n                 13|      5|        2|      9.99|\n                 14|      4|        3|     10.99|\n                 15|      8|        2|      9.99|\n+-------------------+-------+---------+----------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["help(courses_df.join)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ef8ee32b-ea8e-4d0c-adcd-11f27465a9c8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Help on method join in module pyspark.sql.dataframe:\n\njoin(other, on=None, how=None) method of pyspark.sql.dataframe.DataFrame instance\n    Joins with another :class:`DataFrame`, using the given join expression.\n    \n    .. versionadded:: 1.3.0\n    \n    Parameters\n    ----------\n    other : :class:`DataFrame`\n        Right side of the join\n    on : str, list or :class:`Column`, optional\n        a string for the join column name, a list of column names,\n        a join expression (Column), or a list of Columns.\n        If `on` is a string or a list of strings indicating the name of the join column(s),\n        the column(s) must exist on both sides, and this performs an equi-join.\n    how : str, optional\n        default ``inner``. Must be one of: ``inner``, ``cross``, ``outer``,\n        ``full``, ``fullouter``, ``full_outer``, ``left``, ``leftouter``, ``left_outer``,\n        ``right``, ``rightouter``, ``right_outer``, ``semi``, ``leftsemi``, ``left_semi``,\n        ``anti``, ``leftanti`` and ``left_anti``.\n    \n    Examples\n    --------\n    The following performs a full outer join between ``df1`` and ``df2``.\n    \n    &gt;&gt;&gt; from pyspark.sql.functions import desc\n    &gt;&gt;&gt; df.join(df2, df.name == df2.name, &#39;outer&#39;).select(df.name, df2.height)                 .sort(desc(&#34;name&#34;)).collect()\n    [Row(name=&#39;Bob&#39;, height=85), Row(name=&#39;Alice&#39;, height=None), Row(name=None, height=80)]\n    \n    &gt;&gt;&gt; df.join(df2, &#39;name&#39;, &#39;outer&#39;).select(&#39;name&#39;, &#39;height&#39;).sort(desc(&#34;name&#34;)).collect()\n    [Row(name=&#39;Tom&#39;, height=80), Row(name=&#39;Bob&#39;, height=85), Row(name=&#39;Alice&#39;, height=None)]\n    \n    &gt;&gt;&gt; cond = [df.name == df3.name, df.age == df3.age]\n    &gt;&gt;&gt; df.join(df3, cond, &#39;outer&#39;).select(df.name, df3.age).collect()\n    [Row(name=&#39;Alice&#39;, age=2), Row(name=&#39;Bob&#39;, age=5)]\n    \n    &gt;&gt;&gt; df.join(df2, &#39;name&#39;).select(df.name, df2.height).collect()\n    [Row(name=&#39;Bob&#39;, height=85)]\n    \n    &gt;&gt;&gt; df.join(df4, [&#39;name&#39;, &#39;age&#39;]).select(df.name, df.age).collect()\n    [Row(name=&#39;Bob&#39;, age=5)]\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Help on method join in module pyspark.sql.dataframe:\n\njoin(other, on=None, how=None) method of pyspark.sql.dataframe.DataFrame instance\n    Joins with another :class:`DataFrame`, using the given join expression.\n    \n    .. versionadded:: 1.3.0\n    \n    Parameters\n    ----------\n    other : :class:`DataFrame`\n        Right side of the join\n    on : str, list or :class:`Column`, optional\n        a string for the join column name, a list of column names,\n        a join expression (Column), or a list of Columns.\n        If `on` is a string or a list of strings indicating the name of the join column(s),\n        the column(s) must exist on both sides, and this performs an equi-join.\n    how : str, optional\n        default ``inner``. Must be one of: ``inner``, ``cross``, ``outer``,\n        ``full``, ``fullouter``, ``full_outer``, ``left``, ``leftouter``, ``left_outer``,\n        ``right``, ``rightouter``, ``right_outer``, ``semi``, ``leftsemi``, ``left_semi``,\n        ``anti``, ``leftanti`` and ``left_anti``.\n    \n    Examples\n    --------\n    The following performs a full outer join between ``df1`` and ``df2``.\n    \n    &gt;&gt;&gt; from pyspark.sql.functions import desc\n    &gt;&gt;&gt; df.join(df2, df.name == df2.name, &#39;outer&#39;).select(df.name, df2.height)                 .sort(desc(&#34;name&#34;)).collect()\n    [Row(name=&#39;Bob&#39;, height=85), Row(name=&#39;Alice&#39;, height=None), Row(name=None, height=80)]\n    \n    &gt;&gt;&gt; df.join(df2, &#39;name&#39;, &#39;outer&#39;).select(&#39;name&#39;, &#39;height&#39;).sort(desc(&#34;name&#34;)).collect()\n    [Row(name=&#39;Tom&#39;, height=80), Row(name=&#39;Bob&#39;, height=85), Row(name=&#39;Alice&#39;, height=None)]\n    \n    &gt;&gt;&gt; cond = [df.name == df3.name, df.age == df3.age]\n    &gt;&gt;&gt; df.join(df3, cond, &#39;outer&#39;).select(df.name, df3.age).collect()\n    [Row(name=&#39;Alice&#39;, age=2), Row(name=&#39;Bob&#39;, age=5)]\n    \n    &gt;&gt;&gt; df.join(df2, &#39;name&#39;).select(df.name, df2.height).collect()\n    [Row(name=&#39;Bob&#39;, height=85)]\n    \n    &gt;&gt;&gt; df.join(df4, [&#39;name&#39;, &#39;age&#39;]).select(df.name, df.age).collect()\n    [Row(name=&#39;Bob&#39;, age=5)]\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["help(courses_df.crossJoin)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b93e5d26-ebea-4f36-8f9b-f717783c32e3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Help on method crossJoin in module pyspark.sql.dataframe:\n\ncrossJoin(other) method of pyspark.sql.dataframe.DataFrame instance\n    Returns the cartesian product with another :class:`DataFrame`.\n    \n    .. versionadded:: 2.1.0\n    \n    Parameters\n    ----------\n    other : :class:`DataFrame`\n        Right side of the cartesian product.\n    \n    Examples\n    --------\n    &gt;&gt;&gt; df.select(&#34;age&#34;, &#34;name&#34;).collect()\n    [Row(age=2, name=&#39;Alice&#39;), Row(age=5, name=&#39;Bob&#39;)]\n    &gt;&gt;&gt; df2.select(&#34;name&#34;, &#34;height&#34;).collect()\n    [Row(name=&#39;Tom&#39;, height=80), Row(name=&#39;Bob&#39;, height=85)]\n    &gt;&gt;&gt; df.crossJoin(df2.select(&#34;height&#34;)).select(&#34;age&#34;, &#34;name&#34;, &#34;height&#34;).collect()\n    [Row(age=2, name=&#39;Alice&#39;, height=80), Row(age=2, name=&#39;Alice&#39;, height=85),\n     Row(age=5, name=&#39;Bob&#39;, height=80), Row(age=5, name=&#39;Bob&#39;, height=85)]\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Help on method crossJoin in module pyspark.sql.dataframe:\n\ncrossJoin(other) method of pyspark.sql.dataframe.DataFrame instance\n    Returns the cartesian product with another :class:`DataFrame`.\n    \n    .. versionadded:: 2.1.0\n    \n    Parameters\n    ----------\n    other : :class:`DataFrame`\n        Right side of the cartesian product.\n    \n    Examples\n    --------\n    &gt;&gt;&gt; df.select(&#34;age&#34;, &#34;name&#34;).collect()\n    [Row(age=2, name=&#39;Alice&#39;), Row(age=5, name=&#39;Bob&#39;)]\n    &gt;&gt;&gt; df2.select(&#34;name&#34;, &#34;height&#34;).collect()\n    [Row(name=&#39;Tom&#39;, height=80), Row(name=&#39;Bob&#39;, height=85)]\n    &gt;&gt;&gt; df.crossJoin(df2.select(&#34;height&#34;)).select(&#34;age&#34;, &#34;name&#34;, &#34;height&#34;).collect()\n    [Row(age=2, name=&#39;Alice&#39;, height=80), Row(age=2, name=&#39;Alice&#39;, height=85),\n     Row(age=5, name=&#39;Bob&#39;, height=80), Row(age=5, name=&#39;Bob&#39;, height=85)]\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"586f9f05-7e42-43c6-a4aa-b510ea919d88"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"03 Overview of Joins using Spark Data Frames","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":456917195750025}},"nbformat":4,"nbformat_minor":0}