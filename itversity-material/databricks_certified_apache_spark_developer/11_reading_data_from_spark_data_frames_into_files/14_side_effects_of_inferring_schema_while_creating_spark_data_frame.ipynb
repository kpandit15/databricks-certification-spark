{"cells":[{"cell_type":"markdown","source":["* If inferSchema is used entire data need to be read to infer the schema accurately while creating the Data Frame.\n* If the data size is too big then additional time will be spent to infer the schema.\n* When we explicitly specify the schema, data will not be read while creating the Data Frame.\n* As we have seen we should be able to explicitly specify the schema using string or StructType.\n* Inferring Schema will come handy to quickly understand the structure of the data as part of proof of concepts as well as design.\n* Schema will be inferred by default for files of type JSON, Parquet and ORC. Column names and data types will be inferred using metadata that will be associated with these types of files.\n* Inferring the schema on CSV files will create data frames with system generated column names. If inferSchema is used, then the data frame will determine the data types. If the files contain header, then column names can be inherited using it. If not, we need to explicitly pass the columns using `toDF`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3742aac3-373c-4af4-857c-5f159170d86d"}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c9a62b4d-b893-4b48-a219-b7770b629ead"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"14 Side effects of inferring schema while creating Spark Data Frame","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":456917195748380}},"nbformat":4,"nbformat_minor":0}